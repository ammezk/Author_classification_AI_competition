{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"name":"test(lstm).ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dnybj-mWWKIj"},"source":["import pandas as pd\n","import warnings\n","import os\n","from matplotlib import rcParams, pyplot as plt\n","from pathlib import Path\n","warnings.filterwarnings(action='ignore')\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score, log_loss\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.initializers import Constant\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import re\n","from tensorflow import keras\n","from tensorflow.keras import Input, Model, Sequential, layers\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZPhjSVPWj5S"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyWK_BmSWKIw"},"source":["\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    # Restrict TensorFlow to only use the first GPU\n","    try:\n","        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n","    except RuntimeError as e:\n","        # Visible devices must be set before GPUs have been initialized\n","        print(e)\n","else:\n","    print('No GPU detected')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSQ9qxUlWKI2"},"source":["rcParams['figure.figsize'] = (16, 8)\n","plt.style.use('fivethirtyeight')\n","pd.set_option('max_columns', 100)\n","pd.set_option(\"display.precision\", 4)\n","warnings.simplefilter('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z9BRWH2wWKI7"},"source":["# 훈련/테스트 데이터 로드"]},{"cell_type":"code","metadata":{"id":"4fzCqpVHWKI7"},"source":["data_dir = Path('/content/drive/My Drive/OpenSource/final/data')\n","feature_dir = Path('/content/drive/My Drive/OpenSource/final/feature')\n","val_dir = Path('/content/drive/My Drive/OpenSource/final/val')\n","tst_dir = Path('/content/drive/My Drive/OpenSource/final/tst')\n","sub_dir = Path('/content/drive/My Drive/OpenSource/final/sub')\n","dirs = [feature_dir, val_dir, tst_dir, sub_dir]\n","for d in dirs:\n","    os.makedirs(d, exist_ok=True)\n","\n","trn_file = data_dir / 'train.csv'\n","tst_file = data_dir / 'test_x.csv'\n","sample_file = data_dir / 'sample_submission.csv'\n","glove_file = data_dir / 'glove.6B.200d.txt'\n","\n","target_col = 'author'\n","n_fold = 5\n","n_class = 5\n","seed = 42"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"as-hhDofWKI_"},"source":["algo_name = 'gru_non_stopwords'\n","feature_name = 'glove'\n","model_name = f'{algo_name}_{feature_name}'\n","\n","feature_file = feature_dir / f'{feature_name}.csv'\n","p_val_file = val_dir / f'{model_name}.val.csv'\n","p_tst_file = tst_dir / f'{model_name}.tst.csv'\n","sub_file = sub_dir / f'{model_name}.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9A_ByuqyTf-"},"source":["embeddings_index = {}\n","with open(glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","        \n","print(f'Found {len(embeddings_index)} word vectors.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"OCMqJu7rWKJE"},"source":["train = pd.read_csv(trn_file, index_col =0)\n","train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1ZU1RHVWKJI"},"source":["test = pd.read_csv(tst_file, index_col=0)\n","test.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmA8PCeMWKJN"},"source":["### 전처리"]},{"cell_type":"code","metadata":{"id":"TjZP-Se1WKJP"},"source":["#부호를 제거해주는 함수\n","def alpha_num(text):\n","    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n","\n","train['text']=train['text'].apply(alpha_num)\n","\n","# 불용어 제거해주는 함수\n","def remove_stopwords(text):\n","    final_text = []\n","    for i in text.split():\n","        if i.strip().lower() not in stopwords:\n","            final_text.append(i.strip())\n","    return \" \".join(final_text)\n","\n","\n","# 불용어\n","stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n","             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n","             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n","             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n","             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n","             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n","             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n","             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n","             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n","             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n","             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\",\"yours\", \"yourself\", \"yourselves\" ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBIGSt8BWKJb"},"source":["#전처리 적용\n","train['text'] = train['text'].str.lower()\n","test['text'] = test['text'].str.lower()\n","train['text'] = train['text'].apply(alpha_num)#.apply(remove_stopwords)\n","test['text'] = test['text'].apply(alpha_num)#.apply(remove_stopwords)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7u_eJI_SQcYX"},"source":["\n","trn = train['text'].values\n","tst = test['text'].values\n","y = train['author'].values\n","print(trn.shape, tst.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxLrHr1-Qfxz"},"source":["vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=500)\n","text_ds = tf.data.Dataset.from_tensor_slices(trn).batch(128)\n","vectorizer.adapt(text_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fFoHbkkQf2U"},"source":["voc = vectorizer.get_vocabulary()\n","word_index = dict(zip(voc, range(len(voc))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZJqgQ8cQf4U"},"source":["num_tokens = len(voc) + 2\n","embedding_dim = 200\n","hits = 0\n","misses = 0\n","\n","# Prepare embedding matrix\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in embedding index will be all-zeros.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(f\"Converted {hits} words ({misses} misses)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAPFDLGAQvyb"},"source":["embedding_layer = Embedding(\n","    num_tokens,\n","    embedding_dim,\n","    embeddings_initializer=Constant(embedding_matrix),\n","    trainable=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aXeJd1pWKJm"},"source":["### 모델 훈련"]},{"cell_type":"code","metadata":{"id":"swA-eEPKWKJy"},"source":["cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2HBC_x6WKJ2"},"source":["def get_model():\n","   int_sequences_input = Input(shape=(1,), dtype=tf.string)\n","   vectorized_sequences = vectorizer(int_sequences_input)\n","   embedded_sequences = embedding_layer(vectorized_sequences)\n","   x = Bidirectional(GRU(128, dropout = 0.1, return_sequences=True))(embedded_sequences)\n","   x = Bidirectional(GRU(128))(x)\n","   x = Dropout(.3)(x)\n","   preds = Dense(n_class, activation=\"softmax\")(x)\n","   model = Model(int_sequences_input, preds)\n","\n","   # compile model\n","   model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(learning_rate=.01))\n","   return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"x94g9h6AWKJ5"},"source":["p_val = np.zeros((trn.shape[0], n_class))\n","p_tst = np.zeros((tst.shape[0], n_class))\n","for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n","    print(f'training model for CV #{i}')\n","    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n","                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n","\n","    clf = get_model()    \n","    clf.fit(trn[i_trn], \n","            to_categorical(y[i_trn]),\n","            validation_data=(trn[i_val], to_categorical(y[i_val])),\n","            epochs=10,\n","            batch_size=512,\n","            callbacks=[es])\n","    p_val[i_val, :] = clf.predict(trn[i_val])\n","    p_tst += clf.predict(tst) / n_fold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOB4Q--zWKJ9"},"source":["print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n","print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"utOGNXafWKKB"},"source":["np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n","np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kPtfddlyWKKF"},"source":["### 시각화"]},{"cell_type":"code","metadata":{"id":"NXMvfngRWKKG"},"source":["# model summary\n","print(clf.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wg3ui8ELWKKK"},"source":["plot_model(clf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1O0GstYTWKKO"},"source":["### 제출 파일 생성"]},{"cell_type":"code","metadata":{"id":"HJYAHHskWKKO"},"source":["sub = pd.read_csv(sample_file, index_col=0)\n","print(sub.shape)\n","sub.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C28t6p0hWKKS"},"source":["sub[sub.columns] = p_tst\n","sub.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnvNAgwGWKKX"},"source":["sub.to_csv(sub_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiDqNPlGWKKa"},"source":[""],"execution_count":null,"outputs":[]}]}